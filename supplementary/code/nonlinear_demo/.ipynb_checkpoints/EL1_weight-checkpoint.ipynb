{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is demo notebook for Embedding Learning code.\n",
    "Run under: Python3.6, TF1.14.0, gensim3.4.0, numpy1.16.1\n",
    "\n",
    "This demo is based on tuning lam2 in [100, 500, 800, 1000, 1500, 1800] and 5 times reps, the performance can be further improved by more accurate grid searching for lam2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/pyenv/EL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ben/pyenv/EL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ben/pyenv/EL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ben/pyenv/EL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ben/pyenv/EL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ben/pyenv/EL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ben/pyenv/EL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ben/pyenv/EL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ben/pyenv/EL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ben/pyenv/EL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ben/pyenv/EL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ben/pyenv/EL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from data_load_w2v import load_data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import funs\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy import sparse\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from main_EL1_genX import EL_genX\n",
    "from gen_weight import load_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15351506456241032, 697]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "p, d = 300, 2000\n",
    "# weight = sparse.load_npz('weight_matrix.npz')\n",
    "embedding_method = 'googlenews'\n",
    "y = np.load('googlenew_y.npy')\n",
    "input_data = sparse.load_npz('input_X.npz')\n",
    "input_data = normalize(input_data, axis=1, norm='l1')\n",
    "# d = len(dict_emb)\n",
    "\n",
    "senti_data = funs.P_data()\n",
    "senti_data.data = input_data\n",
    "senti_data.id = np.arange(len(y))\n",
    "senti_data.y = y\n",
    "\n",
    "senti_data.weight = load_weight(a=6, b=14, c=7, d=23)\n",
    "senti_data.weight = normalize(senti_data.weight, axis=1, norm='l1')\n",
    "P = sparse.eye(d) - senti_data.weight\n",
    "P = P.T.dot(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ben/MEGA/github/embedding-learning/supplementary/code/nonlinear_demo/main_EL1_genX.py:29: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ben/MEGA/github/embedding-learning/supplementary/code/nonlinear_demo/main_EL1_genX.py:35: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ben/MEGA/github/embedding-learning/supplementary/code/nonlinear_demo/main_EL1_genX.py:61: The name tf.losses.hinge_loss is deprecated. Please use tf.compat.v1.losses.hinge_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ben/pyenv/EL/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ben/MEGA/github/embedding-learning/supplementary/code/nonlinear_demo/main_EL1_genX.py:64: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ben/MEGA/github/embedding-learning/supplementary/code/nonlinear_demo/main_EL1_genX.py:75: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ben/MEGA/github/embedding-learning/supplementary/code/nonlinear_demo/main_EL1_genX.py:78: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "training for lam2: 100\n",
      "Step 1, Loss= 6.4572, Train Accuracy= 0.528, Valid Accuracy= 0.505\n",
      "Step 5, Loss= 4.1532, Train Accuracy= 0.488, Valid Accuracy= 0.540\n",
      "Step 10, Loss= 3.2796, Train Accuracy= 0.509, Valid Accuracy= 0.562\n",
      "Step 15, Loss= 1.6623, Train Accuracy= 0.716, Valid Accuracy= 0.692\n",
      "Step 20, Loss= 1.3954, Train Accuracy= 0.769, Valid Accuracy= 0.720\n",
      "Step 25, Loss= 1.1977, Train Accuracy= 0.717, Valid Accuracy= 0.723\n",
      "Step 30, Loss= 0.8290, Train Accuracy= 0.787, Valid Accuracy= 0.767\n",
      "Step 35, Loss= 0.6896, Train Accuracy= 0.852, Valid Accuracy= 0.755\n",
      "Step 40, Loss= 0.4661, Train Accuracy= 0.873, Valid Accuracy= 0.772\n",
      "Step 45, Loss= 0.4113, Train Accuracy= 0.877, Valid Accuracy= 0.777\n",
      "Step 50, Loss= 0.3312, Train Accuracy= 0.913, Valid Accuracy= 0.788\n",
      "Step 55, Loss= 0.2598, Train Accuracy= 0.923, Valid Accuracy= 0.783\n",
      "Step 60, Loss= 0.2181, Train Accuracy= 0.928, Valid Accuracy= 0.785\n",
      "Step 65, Loss= 0.1783, Train Accuracy= 0.942, Valid Accuracy= 0.785\n",
      "Step 70, Loss= 0.1441, Train Accuracy= 0.947, Valid Accuracy= 0.788\n",
      "Step 75, Loss= 0.1175, Train Accuracy= 0.962, Valid Accuracy= 0.780\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.74\n",
      "training for lam2: 500\n",
      "Step 1, Loss= 2.3571, Train Accuracy= 0.506, Valid Accuracy= 0.535\n",
      "Step 5, Loss= 1.6182, Train Accuracy= 0.592, Valid Accuracy= 0.582\n",
      "Step 10, Loss= 0.9988, Train Accuracy= 0.718, Valid Accuracy= 0.717\n",
      "Step 15, Loss= 0.7071, Train Accuracy= 0.802, Valid Accuracy= 0.760\n",
      "Step 20, Loss= 0.5625, Train Accuracy= 0.823, Valid Accuracy= 0.777\n",
      "Step 25, Loss= 0.4239, Train Accuracy= 0.896, Valid Accuracy= 0.767\n",
      "Step 30, Loss= 0.3180, Train Accuracy= 0.902, Valid Accuracy= 0.800\n",
      "Step 35, Loss= 0.2506, Train Accuracy= 0.929, Valid Accuracy= 0.795\n",
      "Step 40, Loss= 0.2069, Train Accuracy= 0.949, Valid Accuracy= 0.785\n",
      "Step 45, Loss= 0.1637, Train Accuracy= 0.952, Valid Accuracy= 0.800\n",
      "Step 50, Loss= 0.1297, Train Accuracy= 0.959, Valid Accuracy= 0.780\n",
      "Step 55, Loss= 0.1044, Train Accuracy= 0.965, Valid Accuracy= 0.783\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.75333333\n",
      "training for lam2: 800\n",
      "Step 1, Loss= 3.3321, Train Accuracy= 0.449, Valid Accuracy= 0.522\n",
      "Step 5, Loss= 2.1576, Train Accuracy= 0.525, Valid Accuracy= 0.527\n",
      "Step 10, Loss= 1.2416, Train Accuracy= 0.671, Valid Accuracy= 0.658\n",
      "Step 15, Loss= 0.7784, Train Accuracy= 0.798, Valid Accuracy= 0.707\n",
      "Step 20, Loss= 0.6073, Train Accuracy= 0.815, Valid Accuracy= 0.750\n",
      "Step 25, Loss= 0.4883, Train Accuracy= 0.883, Valid Accuracy= 0.757\n",
      "Step 30, Loss= 0.3794, Train Accuracy= 0.890, Valid Accuracy= 0.765\n",
      "Step 35, Loss= 0.3023, Train Accuracy= 0.916, Valid Accuracy= 0.772\n",
      "Step 40, Loss= 0.2454, Train Accuracy= 0.933, Valid Accuracy= 0.780\n",
      "Step 45, Loss= 0.2019, Train Accuracy= 0.945, Valid Accuracy= 0.780\n",
      "Step 50, Loss= 0.1705, Train Accuracy= 0.953, Valid Accuracy= 0.785\n",
      "Step 55, Loss= 0.1451, Train Accuracy= 0.960, Valid Accuracy= 0.780\n",
      "Step 60, Loss= 0.1250, Train Accuracy= 0.966, Valid Accuracy= 0.775\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.79\n",
      "training for lam2: 1000\n",
      "Step 1, Loss= 1.9902, Train Accuracy= 0.597, Valid Accuracy= 0.572\n",
      "Step 5, Loss= 1.4551, Train Accuracy= 0.637, Valid Accuracy= 0.630\n",
      "Step 10, Loss= 0.8598, Train Accuracy= 0.799, Valid Accuracy= 0.680\n",
      "Step 15, Loss= 0.5305, Train Accuracy= 0.832, Valid Accuracy= 0.748\n",
      "Step 20, Loss= 0.3754, Train Accuracy= 0.895, Valid Accuracy= 0.748\n",
      "Step 25, Loss= 0.3141, Train Accuracy= 0.916, Valid Accuracy= 0.743\n",
      "Step 30, Loss= 0.2690, Train Accuracy= 0.915, Valid Accuracy= 0.783\n",
      "Step 35, Loss= 0.2230, Train Accuracy= 0.939, Valid Accuracy= 0.748\n",
      "Step 40, Loss= 0.1767, Train Accuracy= 0.941, Valid Accuracy= 0.765\n",
      "Step 45, Loss= 0.1405, Train Accuracy= 0.953, Valid Accuracy= 0.752\n",
      "Step 50, Loss= 0.1124, Train Accuracy= 0.956, Valid Accuracy= 0.760\n",
      "Step 55, Loss= 0.0919, Train Accuracy= 0.964, Valid Accuracy= 0.757\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77666664\n",
      "training for lam2: 1500\n",
      "Step 1, Loss= 27.9004, Train Accuracy= 0.516, Valid Accuracy= 0.463\n",
      "Step 5, Loss= 4.8868, Train Accuracy= 0.496, Valid Accuracy= 0.440\n",
      "Step 10, Loss= 5.3949, Train Accuracy= 0.491, Valid Accuracy= 0.540\n",
      "Step 15, Loss= 5.7540, Train Accuracy= 0.488, Valid Accuracy= 0.538\n",
      "Step 20, Loss= 3.8094, Train Accuracy= 0.527, Valid Accuracy= 0.567\n",
      "Step 25, Loss= 2.7663, Train Accuracy= 0.569, Valid Accuracy= 0.507\n",
      "Step 30, Loss= 3.1506, Train Accuracy= 0.507, Valid Accuracy= 0.495\n",
      "Step 35, Loss= 2.3087, Train Accuracy= 0.586, Valid Accuracy= 0.535\n",
      "Step 40, Loss= 2.0970, Train Accuracy= 0.680, Valid Accuracy= 0.575\n",
      "Step 45, Loss= 1.8540, Train Accuracy= 0.691, Valid Accuracy= 0.595\n",
      "Step 50, Loss= 1.3906, Train Accuracy= 0.701, Valid Accuracy= 0.600\n",
      "Step 55, Loss= 1.1435, Train Accuracy= 0.769, Valid Accuracy= 0.663\n",
      "Step 60, Loss= 0.8370, Train Accuracy= 0.832, Valid Accuracy= 0.678\n",
      "Step 65, Loss= 0.7138, Train Accuracy= 0.856, Valid Accuracy= 0.720\n",
      "Step 70, Loss= 0.6175, Train Accuracy= 0.880, Valid Accuracy= 0.720\n",
      "Step 75, Loss= 0.5928, Train Accuracy= 0.878, Valid Accuracy= 0.728\n",
      "Step 80, Loss= 0.5745, Train Accuracy= 0.869, Valid Accuracy= 0.738\n",
      "Step 85, Loss= 0.5594, Train Accuracy= 0.868, Valid Accuracy= 0.740\n",
      "Step 90, Loss= 0.5379, Train Accuracy= 0.880, Valid Accuracy= 0.733\n",
      "Step 95, Loss= 0.5178, Train Accuracy= 0.886, Valid Accuracy= 0.730\n",
      "Step 100, Loss= 0.4949, Train Accuracy= 0.892, Valid Accuracy= 0.733\n",
      "Step 105, Loss= 0.4730, Train Accuracy= 0.893, Valid Accuracy= 0.728\n",
      "Step 110, Loss= 0.4523, Train Accuracy= 0.896, Valid Accuracy= 0.730\n",
      "Step 115, Loss= 0.4331, Train Accuracy= 0.897, Valid Accuracy= 0.735\n",
      "Step 120, Loss= 0.4153, Train Accuracy= 0.900, Valid Accuracy= 0.730\n",
      "Step 125, Loss= 0.3971, Train Accuracy= 0.899, Valid Accuracy= 0.728\n",
      "Step 130, Loss= 0.3785, Train Accuracy= 0.900, Valid Accuracy= 0.735\n",
      "Step 135, Loss= 0.3556, Train Accuracy= 0.900, Valid Accuracy= 0.730\n",
      "Step 140, Loss= 0.3287, Train Accuracy= 0.898, Valid Accuracy= 0.728\n",
      "Step 145, Loss= 0.2991, Train Accuracy= 0.897, Valid Accuracy= 0.720\n",
      "Step 150, Loss= 0.2685, Train Accuracy= 0.901, Valid Accuracy= 0.725\n",
      "Step 155, Loss= 0.2394, Train Accuracy= 0.915, Valid Accuracy= 0.717\n",
      "Step 160, Loss= 0.2215, Train Accuracy= 0.914, Valid Accuracy= 0.702\n",
      "Step 165, Loss= 0.2095, Train Accuracy= 0.922, Valid Accuracy= 0.707\n",
      "Step 170, Loss= 0.2004, Train Accuracy= 0.928, Valid Accuracy= 0.705\n",
      "Step 175, Loss= 0.1905, Train Accuracy= 0.933, Valid Accuracy= 0.707\n",
      "Step 180, Loss= 0.1814, Train Accuracy= 0.935, Valid Accuracy= 0.712\n",
      "Step 185, Loss= 0.1743, Train Accuracy= 0.938, Valid Accuracy= 0.712\n",
      "Step 190, Loss= 0.1675, Train Accuracy= 0.938, Valid Accuracy= 0.723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 195, Loss= 0.1613, Train Accuracy= 0.944, Valid Accuracy= 0.723\n",
      "Step 200, Loss= 0.1560, Train Accuracy= 0.948, Valid Accuracy= 0.723\n",
      "Step 205, Loss= 0.1513, Train Accuracy= 0.950, Valid Accuracy= 0.730\n",
      "Step 210, Loss= 0.1468, Train Accuracy= 0.953, Valid Accuracy= 0.730\n",
      "Step 215, Loss= 0.1429, Train Accuracy= 0.955, Valid Accuracy= 0.733\n",
      "Step 220, Loss= 0.1395, Train Accuracy= 0.957, Valid Accuracy= 0.733\n",
      "Step 225, Loss= 0.1371, Train Accuracy= 0.958, Valid Accuracy= 0.735\n",
      "Step 230, Loss= 0.1342, Train Accuracy= 0.959, Valid Accuracy= 0.735\n",
      "Step 235, Loss= 0.1320, Train Accuracy= 0.961, Valid Accuracy= 0.735\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.75166667\n",
      "training for lam2: 1800\n",
      "Step 1, Loss= 2.8462, Train Accuracy= 0.548, Valid Accuracy= 0.515\n",
      "Step 5, Loss= 3.1596, Train Accuracy= 0.504, Valid Accuracy= 0.543\n",
      "Step 10, Loss= 1.5802, Train Accuracy= 0.629, Valid Accuracy= 0.587\n",
      "Step 15, Loss= 1.4815, Train Accuracy= 0.688, Valid Accuracy= 0.625\n",
      "Step 20, Loss= 0.9914, Train Accuracy= 0.720, Valid Accuracy= 0.655\n",
      "Step 25, Loss= 0.6341, Train Accuracy= 0.825, Valid Accuracy= 0.720\n",
      "Step 30, Loss= 0.5869, Train Accuracy= 0.843, Valid Accuracy= 0.720\n",
      "Step 35, Loss= 0.4980, Train Accuracy= 0.849, Valid Accuracy= 0.748\n",
      "Step 40, Loss= 0.4770, Train Accuracy= 0.846, Valid Accuracy= 0.752\n",
      "Step 45, Loss= 0.4126, Train Accuracy= 0.864, Valid Accuracy= 0.757\n",
      "Step 50, Loss= 0.3834, Train Accuracy= 0.878, Valid Accuracy= 0.740\n",
      "Step 55, Loss= 0.3414, Train Accuracy= 0.880, Valid Accuracy= 0.750\n",
      "Step 60, Loss= 0.3102, Train Accuracy= 0.882, Valid Accuracy= 0.757\n",
      "Step 65, Loss= 0.2865, Train Accuracy= 0.896, Valid Accuracy= 0.745\n",
      "Step 70, Loss= 0.2644, Train Accuracy= 0.901, Valid Accuracy= 0.752\n",
      "Step 75, Loss= 0.2484, Train Accuracy= 0.912, Valid Accuracy= 0.750\n",
      "Step 80, Loss= 0.2368, Train Accuracy= 0.923, Valid Accuracy= 0.728\n",
      "Step 85, Loss= 0.2254, Train Accuracy= 0.921, Valid Accuracy= 0.735\n",
      "Step 90, Loss= 0.2144, Train Accuracy= 0.923, Valid Accuracy= 0.740\n",
      "Step 95, Loss= 0.2051, Train Accuracy= 0.927, Valid Accuracy= 0.743\n",
      "Step 100, Loss= 0.1966, Train Accuracy= 0.929, Valid Accuracy= 0.733\n",
      "Step 105, Loss= 0.1899, Train Accuracy= 0.938, Valid Accuracy= 0.728\n",
      "Step 110, Loss= 0.1830, Train Accuracy= 0.941, Valid Accuracy= 0.730\n",
      "Step 115, Loss= 0.1771, Train Accuracy= 0.942, Valid Accuracy= 0.733\n",
      "Step 120, Loss= 0.1719, Train Accuracy= 0.950, Valid Accuracy= 0.735\n",
      "Step 125, Loss= 0.1671, Train Accuracy= 0.953, Valid Accuracy= 0.738\n",
      "Step 130, Loss= 0.1628, Train Accuracy= 0.956, Valid Accuracy= 0.735\n",
      "Step 135, Loss= 0.1588, Train Accuracy= 0.957, Valid Accuracy= 0.735\n",
      "Step 140, Loss= 0.1559, Train Accuracy= 0.958, Valid Accuracy= 0.743\n",
      "Step 145, Loss= 0.1523, Train Accuracy= 0.959, Valid Accuracy= 0.738\n",
      "Step 150, Loss= 0.1496, Train Accuracy= 0.959, Valid Accuracy= 0.743\n",
      "Step 155, Loss= 0.1478, Train Accuracy= 0.961, Valid Accuracy= 0.738\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77166665\n",
      "-----------------------------\n",
      "perform for 0 iteration: 0.770\n"
     ]
    }
   ],
   "source": [
    "echo_perf=[]\n",
    "for j in range(5):\n",
    "    train, valid, test = senti_data.split_data()\n",
    "    echo_cv = []\n",
    "    word_base_mat, acc_valid_orig, acc_test_orig = EL_genX(train, valid, test, p=p)\n",
    "    echo_cv.append([0., acc_valid_orig, acc_test_orig])\n",
    "    init_X = input_data.dot(word_base_mat)\n",
    "    echo = funs.GEC(d=d, p=p)\n",
    "\n",
    "    # Parameters\n",
    "    learning_rate = .005\n",
    "    num_steps = 500\n",
    "    display_step = 5\n",
    "\n",
    "    # Network Parameters\n",
    "    n_hidden = 128\n",
    "    num_input = p\n",
    "    num_classes = 1\n",
    "\n",
    "    X = tf.placeholder(\"float\", [None, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "    A = {\n",
    "        'h1': tf.Variable(tf.random_normal([num_input, n_hidden])),\n",
    "        'h2': tf.Variable(tf.random_normal([n_hidden, n_hidden])),\n",
    "        'h3': tf.Variable(tf.random_normal([n_hidden, n_hidden])),\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden, num_classes]))\n",
    "    }\n",
    "\n",
    "    b = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden])),\n",
    "        'b3': tf.Variable(tf.random_normal([n_hidden])),\n",
    "        'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "    }\n",
    "\n",
    "    # Create model# Creat \n",
    "    def neural_net(x):\n",
    "        # Hidden fully connected layer\n",
    "        layer_1 = tf.add(tf.matmul(x, A['h1']), b['b1'])\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "        layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, A['h2']), b['b2']))\n",
    "        layer_3 = tf.nn.relu(tf.add(tf.matmul(layer_2, A['h3']), b['b3']))\n",
    "        out_layer = tf.matmul(layer_1, A['out']) + b['out']\n",
    "        return out_layer\n",
    "    # lam_range = [1e-3, 1., 10, 100, 500, 800, 1000, 1500, 1800, 2000]\n",
    "    lam_range = [800, 1000, 1500, 1800]\n",
    "    # lam_range = 10**np.arange(-3.,4.,.5)\n",
    "    # for lam1 in lam_range:\n",
    "    for lam2 in lam_range:\n",
    "        print(\"training for lam2: %s\" %lam2)\n",
    "        echo.X = np.copy(init_X)\n",
    "        # Define loss and optimizer\n",
    "        logits = neural_net(X)\n",
    "        loss_op = tf.reduce_mean(tf.losses.hinge_loss(logits=logits, labels=Y))\n",
    "        loss_op = tf.reduce_mean(loss_op)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss_op)\n",
    "        var_grad = tf.gradients(loss_op, [b['b1']])[0]\n",
    "\n",
    "        # Evaluate model (with test logits, for dropout to be disabled)\n",
    "        predicted_class = tf.greater(logits,0.0)\n",
    "        correct_pred = tf.equal(predicted_class, tf.equal(Y,1.0))\n",
    "        # correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "        # Initialize the variables (i.e. assign their default value)\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Start training\n",
    "        with tf.Session() as sess:\n",
    "            opt_valid = 0.\n",
    "        # Run the initializer\n",
    "            sess.run(init)\n",
    "            # learning_rate_embed0 = .1/lam2\n",
    "            learning_rate_embed0 = learning_rate/100.\n",
    "            for step in range(1, num_steps+1):\n",
    "                ## Embedding block\n",
    "                learning_rate_embed = learning_rate_embed0/np.sqrt(step)\n",
    "                A1 = sess.run(A['h1']).T\n",
    "                delta_mat = np.zeros((d, n_hidden))\n",
    "                for i in range(len(train.id)):\n",
    "                    id_tmp = train.id[i]\n",
    "                    X_grad_tmp, y_grad_tmp = echo.X[id_tmp].reshape((1,p)), train.y[i].reshape((1,1))\n",
    "                    delta_mat[id_tmp,:] = sess.run(var_grad, feed_dict={X: X_grad_tmp, Y: y_grad_tmp})\n",
    "                # echo.X -= learning_rate_embed * (delta_mat.dot(A1)/len(train.id) + lam2 * P.dot(echo.X))\n",
    "                echo.X -= learning_rate_embed * lam2 * P.dot(echo.X)\n",
    "                # echo.X -= learning_rate_embed * (delta_mat.dot(A1)/len(train.id) + lam2 * (echo.X - init_X))\n",
    "                ## Learning block\n",
    "                X_tmp, y_tmp = echo.X[train.id], train.y[:, np.newaxis]\n",
    "                sess.run(train_op, feed_dict={X: X_tmp, Y: y_tmp})\n",
    "                acc_valid = sess.run(accuracy, feed_dict={X: echo.X[valid.id], Y: valid.y[:, np.newaxis]})\n",
    "\n",
    "                if step % display_step == 0 or step == 1:\n",
    "                # Calculate batch loss and accuracy\n",
    "                    loss, acc = sess.run([loss_op, accuracy], feed_dict={X: X_tmp, Y: y_tmp})\n",
    "                    print(\"Step \" + str(step) + \", Loss= \" + \\\n",
    "                        \"{:.4f}\".format(loss) + \", Train Accuracy= \" + \\\n",
    "                        \"{:.3f}\".format(acc) + \", Valid Accuracy= \" + \\\n",
    "                        \"{:.3f}\".format(acc_valid))\n",
    "                    if acc > .96:\n",
    "                        break\n",
    "            print(\"Optimization Finished!\")\n",
    "            # Calculate accuracy for PPI test\n",
    "            acc_test = sess.run(accuracy, feed_dict={X: echo.X[test.id], Y: test.y[:, np.newaxis]})\n",
    "            print(\"Testing Accuracy:\", acc_test)\n",
    "        echo_cv.append([lam2, acc_valid, acc_test])\n",
    "    echo_cv = np.array(echo_cv)\n",
    "    echo_perf_tmp = echo_cv[np.argmax(echo_cv[:,1]), 2]\n",
    "    print('-----------------------------')\n",
    "    print(\"perform for %s iteration: %.3f\" %(j, echo_perf_tmp))\n",
    "    echo_perf.append(echo_perf_tmp)\n",
    "echo_perf = np.array(echo_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('echo perf: %.3f(%.3f)' %(1.-echo_perf.mean(), echo_perf.std()/np.sqrt(5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".EL",
   "language": "python",
   "name": ".el"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
